{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bb1936-0dfc-467f-9a1e-841b641e4984",
   "metadata": {},
   "source": [
    "# ASSOCIATION RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e613b1e-7493-4a95-aae9-15a349856b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8418d3d-bc67-4b79-87e2-3ae47c284f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (3.8.4)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.4 MB 1.3 MB/s eta 0:00:02\n",
      "    --------------------------------------- 0.0/1.4 MB 1.3 MB/s eta 0:00:02\n",
      "    --------------------------------------- 0.0/1.4 MB 1.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.4 MB 744.7 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.4 MB 744.7 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 841.6 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 841.6 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.4 MB 905.4 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.4 MB 905.4 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.4/1.4 MB 794.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.4/1.4 MB 791.2 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.4/1.4 MB 793.8 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.5/1.4 MB 797.2 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.5/1.4 MB 839.3 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.5/1.4 MB 839.3 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.6/1.4 MB 754.8 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.6/1.4 MB 775.4 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.6/1.4 MB 775.4 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.7/1.4 MB 785.9 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.4 MB 785.9 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.4 MB 795.1 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.4 MB 795.1 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.4 MB 755.9 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 759.9 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.4 MB 762.8 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.9/1.4 MB 768.9 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.4 MB 761.9 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.4 MB 761.9 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 754.3 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 760.5 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 733.5 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.4 MB 747.0 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.4 MB 747.0 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.4 MB 726.8 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.2/1.4 MB 737.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.2/1.4 MB 737.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.2/1.4 MB 737.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.3/1.4 MB 753.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 769.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 770.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 767.6 kB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030f89a-8a54-4683-97e6-b33b9e65b0ba",
   "metadata": {},
   "source": [
    "## Association Rule Mining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0044c15b-a790-4376-b623-c6697c350bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded dataset:\n",
      "Product         Beer  Bread  Butter  Diapers  Milk\n",
      "Transaction_ID                                    \n",
      "1                  0      1       0        0     1\n",
      "2                  1      0       0        1     1\n",
      "3                  0      1       1        0     0\n",
      "4                  0      1       0        1     1\n",
      "5                  1      1       0        0     0\n",
      "\n",
      "Frequent Itemsets:\n",
      "   support         itemsets\n",
      "0      0.4           (Beer)\n",
      "1      0.8          (Bread)\n",
      "2      0.4        (Diapers)\n",
      "3      0.6           (Milk)\n",
      "4      0.4    (Milk, Bread)\n",
      "5      0.4  (Milk, Diapers)\n",
      "\n",
      "Association Rules:\n",
      "  antecedents consequents  support  confidence      lift\n",
      "2      (Milk)   (Diapers)      0.4    0.666667  1.666667\n",
      "3   (Diapers)      (Milk)      0.4    1.000000  1.666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Step 1: Load or create a dataset\n",
    "# Example dataset: Transactions of products\n",
    "data = {\n",
    "    'Transaction_ID': [1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5],\n",
    "    'Product': ['Milk', 'Bread', 'Milk', 'Diapers', 'Beer', \n",
    "                'Bread', 'Butter', 'Milk', 'Bread', 'Diapers', \n",
    "                'Bread', 'Beer']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Pre-process the data to get a one-hot encoded table\n",
    "basket = df.pivot_table(index='Transaction_ID', columns='Product', aggfunc=lambda x: 1, fill_value=0)\n",
    "\n",
    "print(\"One-hot encoded dataset:\")\n",
    "print(basket)\n",
    "\n",
    "# Step 3: Apply the Apriori algorithm to find frequent itemsets\n",
    "min_support = 0.3  # Minimum support threshold\n",
    "frequent_itemsets = apriori(basket, min_support=min_support, use_colnames=True)\n",
    "\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Step 4: Generate association rules\n",
    "min_confidence = 0.5  # Minimum confidence threshold\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "# Filter rules by lift (optional)\n",
    "rules = rules[rules['lift'] > 1]  # Only keep rules with lift > 1\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "\n",
    "# Optional: Save the rules to a CSV file\n",
    "rules.to_csv('association_rules.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b80e9-e25f-439a-bb99-d71b0a3eeaf7",
   "metadata": {},
   "source": [
    "## Analysis and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "032e84b8-89b7-4c1e-88a3-241d89f5c98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Rules Sorted by Lift:\n",
      "  antecedents consequents  support  confidence      lift\n",
      "2      (Milk)   (Diapers)      0.4    0.666667  1.666667\n",
      "3   (Diapers)      (Milk)      0.4    1.000000  1.666667\n",
      "\n",
      "Rules with High Confidence (> 0.7):\n",
      "  antecedents consequents  support  confidence      lift\n",
      "3   (Diapers)      (Milk)      0.4         1.0  1.666667\n",
      "\n",
      "Rules Involving 'Milk' as an Antecedent:\n",
      "  antecedents consequents  support  confidence      lift\n",
      "2      (Milk)   (Diapers)      0.4    0.666667  1.666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Sample Data\n",
    "data = {\n",
    "    'Transaction_ID': [1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5],\n",
    "    'Product': ['Milk', 'Bread', 'Milk', 'Diapers', 'Beer', \n",
    "                'Bread', 'Butter', 'Milk', 'Bread', 'Diapers', \n",
    "                'Bread', 'Beer']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: One-hot encode the dataset\n",
    "basket = df.pivot_table(index='Transaction_ID', columns='Product', aggfunc=lambda x: 1, fill_value=0)\n",
    "\n",
    "# Step 2: Apply the Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(basket, min_support=0.3, use_colnames=True)\n",
    "\n",
    "# Step 3: Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "rules = rules[rules['lift'] > 1]  # Only keep rules with lift > 1\n",
    "\n",
    "# Step 4: Analyze the rules for insights\n",
    "def analyze_rules(rules):\n",
    "    print(\"\\nTop Rules Sorted by Lift:\")\n",
    "    top_lift_rules = rules.sort_values(by='lift', ascending=False).head(5)\n",
    "    print(top_lift_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "\n",
    "    print(\"\\nRules with High Confidence (> 0.7):\")\n",
    "    high_conf_rules = rules[rules['confidence'] > 0.7]\n",
    "    print(high_conf_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "\n",
    "    print(\"\\nRules Involving 'Milk' as an Antecedent:\")\n",
    "    milk_rules = rules[rules['antecedents'].apply(lambda x: 'Milk' in x)]\n",
    "    print(milk_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "\n",
    "# Call the analysis function\n",
    "analyze_rules(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828e63e-c99b-41d7-9649-0c35a9d6a3b7",
   "metadata": {},
   "source": [
    "## Interview Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d1e99-a04e-4f9c-b582-5034bd662624",
   "metadata": {},
   "source": [
    "# 1.What is lift and why is it important in Association rules?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba2270-609d-457c-9518-f86ec92308b8",
   "metadata": {},
   "source": [
    "Lift is a key metric used in Association Rule Mining to measure the strength of a rule. It tells us how much more likely the consequent (right-hand side of the rule) is to occur given the antecedent (left-hand side), compared to when the consequent occurs independently.\n",
    "\n",
    "In other words, lift quantifies the degree to which two products are dependent on each other, or whether their co-occurrence is more than what would be expected by chance.\n",
    "\n",
    "Formula for Lift:\n",
    "Lift(A->B)=Confidence(A->B)/Support(B)\n",
    "​\n",
    " Where:\n",
    "\n",
    "Confidence(A → B) = P(B | A) = The probability of buying B, given that A was bought.\n",
    "Support(B) = P(B) = The probability that B occurs independently.\n",
    "\n",
    "\n",
    "\n",
    "Interpretation of Lift Values\n",
    "* Lift > 1:\n",
    "\n",
    "1 The occurrence of A increases the likelihood of B.\n",
    "2 A and B are positively correlated, meaning they are more likely to be purchased together than by random chance.\n",
    " \n",
    "* Lift = 1:\n",
    "\n",
    "1 A and B are independent of each other.\n",
    "2 The presence of A has no effect on the likelihood of B.\n",
    "\n",
    "* Lift < 1:\n",
    "\n",
    "1 The occurrence of A reduces the likelihood of B.\n",
    "2 A and B are negatively correlated, meaning they are less likely to occur together than expected by chance.\n",
    "Why is Lift Important in Association Rules?\n",
    "1 Evaluates True Strength of a Rule:\n",
    "\n",
    " * Unlike confidence, which only considers the proportion of transactions containing both items, lift accounts for the baseline occurrence of the consequent. It tells us if the rule has real value beyond what would occur by chance.\n",
    "\n",
    "2 Removes Bias from Frequent Items:\n",
    "\n",
    " * Items with high support (e.g., bread, milk) might appear frequently with many other items, resulting in high confidence values. Lift helps filter out trivial associations by checking if the association is stronger than expected by chance.\n",
    "\n",
    "3 Identifies Interesting Relationships:\n",
    "\n",
    "* Rules with high lift values highlight products that are highly associated, which can be used for product bundling, promotions, or cross-selling strategies.\n",
    "\n",
    "4 Helps in Prioritization:\n",
    " * Business decisions like store layout and targeted marketing require identifying the most meaningful associations. Lift enables better prioritization by focusing on rules with the highest impact.\n",
    "\n",
    "\n",
    "Example:\n",
    "If:\n",
    "\n",
    "40% of transactions contain Milk (Support(Milk) = 0.4)\n",
    "\n",
    "50% of transactions contain Bread (Support(Bread) = 0.5)\n",
    "\n",
    "20% of transactions contain both Milk and Bread (Support(Milk ∩ Bread) = 0.2)\n",
    "\n",
    "Confidence(Milk → Bread) = 0.2 / 0.4 = 0.5\n",
    "Using the Lift formula:\n",
    "\n",
    "Lift(Milk->Bread)=0.5/0.5=1\n",
    "\n",
    "In this case, the lift is 1, meaning buying Milk does not increase or decrease the likelihood of buying Bread beyond what would be expected by chance.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Lift is a crucial metric in Association Rule Mining because it helps us differentiate between meaningful and trivial relationships. By focusing on rules with lift > 1, businesses can identify opportunities to improve product bundling, promotions, and marketing strategies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88753bd8-f536-4724-8e86-bcb4732ed66b",
   "metadata": {},
   "source": [
    "## 2.What is support and Confidence. How do you calculate them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f8b46-03b0-4644-8945-5948c60b659e",
   "metadata": {},
   "source": [
    " 1 What is Support in Association Rules?\n",
    "\n",
    "Support measures how frequently an itemset or rule appears in the dataset. It reflects the proportion of transactions in which a particular product (or combination of products) occurs. It is useful for identifying popular items or itemsets.\n",
    "\n",
    "Formula for Support:\n",
    "Support(A->B)=Transactions containing both A and B/Total number of transactions\n",
    " \n",
    " * Support(A ∩ B): The percentage of transactions that contain both A and B.\n",
    "* Support Threshold: A predefined value (e.g., 0.3 or 30%) used to filter out infrequent itemsets.\n",
    "\n",
    " Example of Support Calculation:\n",
    "\n",
    "If there are 10 transactions, and 3 of them contain both Milk and Bread, then:\n",
    "\n",
    "Support(milk->Bread)=3/10=0.3\n",
    "So, the support for the rule is 0.3, meaning 30% of the transactions contain both Milk and Bread.\n",
    "\n",
    "2 What is Confidence in Association Rules?\n",
    "Confidence measures the proportion of transactions that contain the antecedent (A), which also contain the consequent (B). It indicates the likelihood of purchasing B given that A has already been purchased.\n",
    "\n",
    "Formula for Confidence:\n",
    "Confidence(A->B)=Transactions containing both A and B/Transactions containing A\n",
    " \n",
    " * Confidence(A → B): The probability of buying B when A has been purchased.\n",
    " * Confidence Threshold: A predefined value (e.g., 0.5 or 50%) to filter out weak rules.\n",
    "Example of Confidence Calculation:\n",
    "If:\n",
    "\n",
    " * 5 transactions contain Milk\n",
    " * 3 of those transactions also contain Bread\n",
    "\n",
    "     \n",
    "Then:\n",
    "\n",
    "Confidence(Milk->Bread)=3/5=0.6\n",
    "\n",
    "This means that 60% of the time, when Milk is purchased, Bread is also purchased.\n",
    "\n",
    "Support vs Confidence:\n",
    "    \n",
    " 1 Support helps identify frequent itemsets or product combinations across the entire dataset.\n",
    " 2 Confidence indicates the strength of a rule by measuring the likelihood of one product being purchased given the purchase of another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb8805-3288-4bdd-9552-7660da01611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Example for Support and Confidence Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b85794f-37f6-414b-981f-7874fc57b3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets with Support >= 0.2:\n",
      "    support                itemsets\n",
      "0       0.4                  (Beer)\n",
      "1       0.8                 (Bread)\n",
      "2       0.2                (Butter)\n",
      "3       0.4               (Diapers)\n",
      "4       0.6                  (Milk)\n",
      "5       0.2           (Beer, Bread)\n",
      "6       0.2         (Beer, Diapers)\n",
      "7       0.2            (Beer, Milk)\n",
      "8       0.2         (Butter, Bread)\n",
      "9       0.2        (Bread, Diapers)\n",
      "10      0.4           (Milk, Bread)\n",
      "11      0.4         (Milk, Diapers)\n",
      "12      0.2   (Beer, Milk, Diapers)\n",
      "13      0.2  (Milk, Bread, Diapers)\n",
      "\n",
      "Association Rules:\n",
      "         antecedents      consequents  support  confidence\n",
      "0             (Beer)          (Bread)      0.2    0.500000\n",
      "1             (Beer)        (Diapers)      0.2    0.500000\n",
      "2          (Diapers)           (Beer)      0.2    0.500000\n",
      "3             (Beer)           (Milk)      0.2    0.500000\n",
      "4           (Butter)          (Bread)      0.2    1.000000\n",
      "5          (Diapers)          (Bread)      0.2    0.500000\n",
      "6             (Milk)          (Bread)      0.4    0.666667\n",
      "7            (Bread)           (Milk)      0.4    0.500000\n",
      "8             (Milk)        (Diapers)      0.4    0.666667\n",
      "9          (Diapers)           (Milk)      0.4    1.000000\n",
      "10      (Beer, Milk)        (Diapers)      0.2    1.000000\n",
      "11   (Beer, Diapers)           (Milk)      0.2    1.000000\n",
      "12   (Milk, Diapers)           (Beer)      0.2    0.500000\n",
      "13            (Beer)  (Milk, Diapers)      0.2    0.500000\n",
      "14         (Diapers)     (Beer, Milk)      0.2    0.500000\n",
      "15     (Milk, Bread)        (Diapers)      0.2    0.500000\n",
      "16   (Milk, Diapers)          (Bread)      0.2    0.500000\n",
      "17  (Bread, Diapers)           (Milk)      0.2    1.000000\n",
      "18         (Diapers)    (Milk, Bread)      0.2    0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Sample Data: Transactions with multiple products\n",
    "data = {\n",
    "    'Transaction_ID': [1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5],\n",
    "    'Product': ['Milk', 'Bread', 'Milk', 'Diapers', 'Beer', \n",
    "                'Bread', 'Butter', 'Milk', 'Bread', 'Diapers', \n",
    "                'Bread', 'Beer']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Create a one-hot encoded dataset\n",
    "basket = df.pivot_table(index='Transaction_ID', columns='Product', aggfunc=lambda x: 1, fill_value=0)\n",
    "\n",
    "# Step 2: Generate frequent itemsets using the Apriori algorithm\n",
    "frequent_itemsets = apriori(basket, min_support=0.2, use_colnames=True)\n",
    "\n",
    "print(\"\\nFrequent Itemsets with Support >= 0.2:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Step 3: Generate association rules with minimum confidence of 0.5\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a73b3f-f7e9-4b76-85c4-71e19579347d",
   "metadata": {},
   "source": [
    "## 3 What are some limitations or challenges of Association rules mining?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25783f70-dc0d-4d95-a5a9-6380e2e0d638",
   "metadata": {},
   "source": [
    "Association rule mining is a powerful technique for discovering interesting relationships in large datasets, particularly in market basket analysis. However, it comes with several limitations and challenges that can affect the quality and applicability of the results. Here are some key limitations:\n",
    "\n",
    "1. High Computational Complexity\n",
    " * Scalability Issues: The algorithm can become computationally intensive as the dataset size increases, particularly with a large number of items. This can lead to long processing times and high memory usage.\n",
    " * Exponential Growth of Itemsets: As the number of items increases, the number of possible itemsets grows exponentially, making it challenging to compute frequent itemsets efficiently.\n",
    "2. Choice of Parameters\n",
    "* Support and Confidence Thresholds: Choosing the right thresholds for support and confidence is crucial but can be subjective.\n",
    "* Low Thresholds: May yield too many trivial or uninteresting rules.\n",
    "* High Thresholds: Might filter out potentially useful rules, leading to loss of meaningful associations.\n",
    "3. Interpretability of Results\n",
    "* Large Number of Rules: The algorithm can generate a large number of association rules, making it difficult to identify the most relevant ones.\n",
    "* Complexity of Relationships: Rules may not adequately capture the complexity of relationships between items, especially in more nuanced datasets.\n",
    "4. Data Quality and Preprocessing\n",
    "* Missing or Noisy Data: The presence of missing, incomplete, or noisy data can lead to misleading results and affect the reliability of the rules.\n",
    "* Data Transformation: Effective transformation of data into a suitable format for mining is essential. Poor preprocessing can lead to poor-quality output.\n",
    "5. Sparsity of Data\n",
    "In datasets with a large number of items but relatively few transactions, many potential itemsets will have low support, leading to a sparsity issue. This makes it challenging to find meaningful associations.\n",
    "6. Overfitting\n",
    "The algorithm may identify associations that do not generalize well to new data, leading to overfitting. This is particularly a risk when rules are created based on high confidence without considering support or lift.\n",
    "7. Lack of Context\n",
    "Contextual Information: Association rules do not account for temporal or contextual information (e.g., seasonality, promotions) that might influence buying behavior. This limits their applicability in dynamic environments.\n",
    "8. Causality vs. Correlation\n",
    "Misinterpretation of Rules: Association rules indicate correlation but do not imply causation. Users may mistakenly assume that a strong association implies that purchasing one item causes the purchase of another, which is not necessarily true.\n",
    "9. Simplicity of the Model\n",
    "Association rule mining assumes that the relationship between items is independent. It does not consider interactions between items that might alter their association.\n",
    "10. Single-level Analysis\n",
    "Single-Level Mining: Traditional association rule mining does not capture hierarchical or multi-level relationships between products, limiting insights in more complex datasets.\n",
    "\n",
    "Conclusion\n",
    "While association rule mining provides valuable insights, practitioners must be aware of these limitations and challenges. Careful parameter selection, preprocessing, and validation of results are essential to enhance the effectiveness of the analysis. Combining association rule mining with other data analysis techniques (e.g., clustering, classification) can also help mitigate some of these challenges and yield more robust insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69773c-2b0e-42eb-9c69-0ec5121bc403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775802c8-0bd1-4634-a150-300ec938bfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab6d18-0183-4cf4-9c55-f9f3656ee779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9f7db0-30b6-4e64-bc2b-b67af944b97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d239d96-0bac-4c18-b453-a879a0512590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc3f08-13c3-4ec4-8981-b69d60caa3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
